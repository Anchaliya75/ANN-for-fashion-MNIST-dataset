{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building an Artificial Neural Network in TensorFlow 2.0 for fashion MNIST dataset.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM0DXrA2OOcWgFrxViwAQQ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mesushan/ANN-for-fashion-MNIST-dataset/blob/master/Building_an_Artificial_Neural_Network_in_TensorFlow_2_0_for_fashion_MNIST_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6KvWsyb9FT-",
        "colab_type": "text"
      },
      "source": [
        "Data Source: [Kaggle](https://www.kaggle.com/zalando-research/fashionmnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSVTwEbu9Q4T",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Installing dependencies and setting up a GPU environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RasNSyP49MTc",
        "colab_type": "code",
        "outputId": "80a4d05e-5ec8-4291-9bad-ba8a3bd8c27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.1-rc0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.1-rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/24/f94a1b8f779471f53b814a96c5109994ccf65b0103b771ff208c8a937d37/tensorflow_gpu-2.1.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (402.3MB)\n",
            "\u001b[K     |████████████████████████████████| 402.3MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (0.1.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (3.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (0.34.2)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (2.0.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (2.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1-rc0) (1.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu==2.1-rc0) (45.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1-rc0) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (2.21.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (0.16.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (1.11.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (3.1.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (4.0.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.1-rc0) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "  Found existing installation: tensorflow-gpu 2.0.0\n",
            "    Uninstalling tensorflow-gpu-2.0.0:\n",
            "      Successfully uninstalled tensorflow-gpu-2.0.0\n",
            "Successfully installed tensorflow-gpu-2.1.0rc0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow",
                  "tensorflow_core"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXyXUi3t9-qS",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Importing the libraries and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKwFOKzP9jP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KphoUvHE-EJV",
        "colab_type": "code",
        "outputId": "95c2c98c-0def-47cc-f9c7-289e601e0498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0-rc0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPvRKok6-LdX",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8So9t6Kj-Svo",
        "colab_type": "text"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfSe1W5y-I9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2JX9UiV-dkl",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the images\n",
        "\n",
        "We divide each pixel of the image in the training and test sets by the maximum number of pixels (255).\n",
        "\n",
        "In this way each pixel will be in the range [0, 1]. By normalizing images we make sure that our model (ANN) trains faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRhhozmS-VwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWsaj2nb-uKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = X_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WE7Bfic-1H6",
        "colab_type": "text"
      },
      "source": [
        "### Reshaping the dataset\n",
        "\n",
        "Since we are building a fully connected network, we reshape the training set and the test set to be into the vector format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeMdHKR_-2ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since each image's dimension is 28x28, we reshape the full dataset to [-1 (all elements), height * width]\n",
        "X_train = X_train.reshape(-1, 28*28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2O5Adxn_FN5",
        "colab_type": "code",
        "outputId": "8eab02cd-113e-47fc-9d48-7217c0d133c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx-x8h_U_HxF",
        "colab_type": "code",
        "outputId": "014f780c-1cd0-4509-d6bf-939522316900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgjhIMjw_UjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We reshape the test set the same way as train set\n",
        "X_test = X_test.reshape(-1, 28*28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpIBoC0V_WF_",
        "colab_type": "code",
        "outputId": "6eb4b8b0-6a9f-4440-9637-9220133106a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXAg7wja_fT1",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Building an Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxAWY4a8_k7Q",
        "colab_type": "text"
      },
      "source": [
        "### Defining the model\n",
        "\n",
        "We simply define an object of the Sequential model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq8CDcBm_YK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h59KmSBp_zFj",
        "colab_type": "text"
      },
      "source": [
        "### Adding a first fully-connected hidden layer\n",
        "\n",
        "Layer hyper-parameters to be used:\n",
        "- number of units/neurons: 128\n",
        "- activation function: ReLU\n",
        "- input_shape: (784, )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXlpnive_vk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784, )))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ8fV0JSAKmC",
        "colab_type": "text"
      },
      "source": [
        "### Adding a second layer with Dropout\n",
        "\n",
        "Dropout is being used as it is a Regularization technique where we randomly set neurons in a layer to zero. That way while training those neurons won't be updated. Because some percentage of neurons won't be updated the whole training process is long and we have less chance for overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGZ9tnBkAJhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDWr_9ZxAjvI",
        "colab_type": "text"
      },
      "source": [
        "### Adding the output layer\n",
        "\n",
        "- units: number of classes (10 in the Fashion MNIST dataset)\n",
        "- activation: softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbhy4VMIAfsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IroC3Vw9AyLg",
        "colab_type": "text"
      },
      "source": [
        "### Compiling the model\n",
        "\n",
        "- Optimizer: Adam\n",
        "- Loss: Sparse softmax (categorical) crossentropy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U04P-byGAtxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lICFqP8bBKpw",
        "colab_type": "code",
        "outputId": "36d0816e-0a39-4ded-b90f-b739fbcad8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15dMBTpbBap3",
        "colab_type": "text"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq2BfL_kBVlY",
        "colab_type": "code",
        "outputId": "b1046d41-dcdc-4cd4-bf1a-e0997d81716a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.5297 - sparse_categorical_accuracy: 0.8128\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3970 - sparse_categorical_accuracy: 0.8547\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3641 - sparse_categorical_accuracy: 0.8662\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3440 - sparse_categorical_accuracy: 0.8736\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3293 - sparse_categorical_accuracy: 0.8792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff06002feb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0-15akSBtjU",
        "colab_type": "text"
      },
      "source": [
        "### Model evaluation and prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2YRTnykBhsD",
        "colab_type": "code",
        "outputId": "4a7cf493-705f-4d6a-9dbf-14425b5b00c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 65us/sample - loss: 0.3606 - sparse_categorical_accuracy: 0.8700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkxH19BmBxcW",
        "colab_type": "code",
        "outputId": "358b15a5-5dc8-49bc-9bde-882f6548adc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Test loss: {}\".format(test_loss))\n",
        "print(\"Test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.3605656342029572\n",
            "Test accuracy: 0.8700000047683716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJx29Ah4B4RG",
        "colab_type": "text"
      },
      "source": [
        "###### From the above ANN, we see that our model makes the accuracy of 87% in test dataset which is approximately similar to the last epoch in training set without any parameter tunings, thanks to the dropout we used which prevent overfitting. The next step will be do to some parameter tuning and see if the model makes good predictions."
      ]
    }
  ]
}